{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.5 - Issue with the gradient\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data_df = pd.read_csv('bike-sharing.csv')\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x/y arrays\n",
    "x = 47*data_df.temp.values - 8 # Degrees Celsius\n",
    "y = data_df.users.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compare the two version\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(7, 3))\n",
    "ax1.scatter(data_df.temp, y, s=15)\n",
    "ax1.set_xlabel('temperatures (rescaled)')\n",
    "ax1.set_ylabel('users')\n",
    "ax2.scatter(x, y, s=15)\n",
    "ax2.set_xlabel('temperatures in Â°C')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialization\n",
    "lr = 0.7\n",
    "a, b = 0, 0\n",
    "n_steps = 400\n",
    "\n",
    "# Root mean square error (RMSE)\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(y - y_pred)))\n",
    "\n",
    "# Gradient descent\n",
    "log_rmse = []\n",
    "for step in range(n_steps):\n",
    "    # Compute partial derivatives\n",
    "    y_pred = a*x + b\n",
    "    error = y - y_pred\n",
    "    a_grad = -2*np.mean(x*error)\n",
    "    b_grad = -2*np.mean(error)\n",
    "    \n",
    "    # Update parameters\n",
    "    a -= lr*a_grad\n",
    "    b -= lr*b_grad\n",
    "    \n",
    "    # Log RMSE score\n",
    "    log_rmse.append(rmse(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RMSE values\n",
    "plt.plot(log_rmse, label='learning rate: {}'.format(lr))\n",
    "plt.title('RMSE after {} steps is {}'.format(n_steps, log_rmse[-1]))\n",
    "plt.xlabel(\"time step\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x/y arrays\n",
    "x = data_df.temp.values\n",
    "y = data_df.users.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "lr = 0.7\n",
    "a, b = 0, 0\n",
    "n_steps = 400\n",
    "\n",
    "# Gradient descent\n",
    "log_a = [a]\n",
    "log_b = [b]\n",
    "\n",
    "for step in range(n_steps):\n",
    "    # Compute partial derivatives\n",
    "    y_pred = a*x + b\n",
    "    error = y - y_pred\n",
    "    a_grad = -2*np.mean(x*error)\n",
    "    b_grad = -2*np.mean(error)\n",
    "    \n",
    "    # Update parameters\n",
    "    a -= lr*a_grad\n",
    "    b -= lr*b_grad\n",
    "    \n",
    "    # Log a, b values\n",
    "    log_a.append(a)\n",
    "    log_b.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize steps\n",
    "plt.plot(log_a, log_b)\n",
    "plt.grid()\n",
    "plt.xlabel('parameter a')\n",
    "plt.ylabel('parameter b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the error surface\n",
    "def visualize_steps(fig, axis, log_a, log_b, x, y):\n",
    "    # Define a grid of a,b parameters\n",
    "    min_ab = min(min(log_a), min(log_b))\n",
    "    max_ab = max(max(log_a), max(log_b))\n",
    "\n",
    "    d = max_ab - min_ab\n",
    "    min_ab -= d * 0.1\n",
    "    max_ab += d * 0.1\n",
    "\n",
    "    a = np.linspace(min_ab, max_ab, num=40)\n",
    "    b = np.linspace(min_ab, max_ab, num=40)\n",
    "    a_grid, b_grid = np.meshgrid(a, b)\n",
    "\n",
    "    # Compute the RMSE score for each a,b pair on that grid\n",
    "    rmse_grid = np.zeros_like(a_grid)\n",
    "\n",
    "    for i in range(40):\n",
    "        for j in range(40):\n",
    "            a, b = a_grid[i, j], b_grid[i, j]\n",
    "            rmse_grid[i, j] = rmse(a*x+b, y)\n",
    "\n",
    "    # RMSE surface\n",
    "    axis.set_aspect('equal', adjustable='box')\n",
    "    mpl_contourset = axis.contourf(a_grid, b_grid, rmse_grid, 20, cmap=plt.cm.coolwarm)\n",
    "    fig.colorbar(mpl_contourset, ax=axis, label='RMSE')\n",
    "\n",
    "    # Plot the GD steps\n",
    "    axis.plot(log_a, log_b, c='#00abe9')\n",
    "    axis.scatter(log_a, log_b, c='#00abe9')\n",
    "\n",
    "    # Set titles and labels\n",
    "    axis.set_xlabel('parameter a')\n",
    "    axis.set_ylabel('parameter b')\n",
    "\n",
    "    axis.set_xlim(min_ab, max_ab)\n",
    "    axis.set_ylim(min_ab, max_ab)\n",
    "    \n",
    "# Plot the error surface\n",
    "fig = plt.figure()\n",
    "visualize_steps(fig, fig.gca(), log_a, log_b, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.6 - Standardization\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# Standardize x\n",
    "x_standardized = scale(x)\n",
    "\n",
    "print('Mean:', x_standardized.mean())\n",
    "print('Standard deviation:', x_standardized.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "lr = 0.7\n",
    "a, b = 0, 0\n",
    "n_steps = 400\n",
    "\n",
    "# Gradient descent\n",
    "log_a = [a]\n",
    "log_b = [b]\n",
    "\n",
    "for step in range(n_steps):\n",
    "    # Compute partial derivatives\n",
    "    y_pred = a*x_standardized + b\n",
    "    error = y - y_pred\n",
    "    a_grad = -2*np.mean(x_standardized*error)\n",
    "    b_grad = -2*np.mean(error)\n",
    "    \n",
    "    # Update parameters\n",
    "    a -= lr*a_grad\n",
    "    b -= lr*b_grad\n",
    "    \n",
    "    # Log a, b values\n",
    "    log_a.append(a)\n",
    "    log_b.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the error surface\n",
    "fig = plt.figure()\n",
    "visualize_steps(fig, fig.gca(), log_a, log_b, x_standardized, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
